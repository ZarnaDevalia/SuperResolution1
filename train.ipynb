{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from model import evaluate\n",
    "from model import srgan\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "from model.srgan import generator, discriminator\n",
    "from data import DIV2K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, loss, learning_rate, checkpoint_dir):\n",
    "        self.now = None\n",
    "        self.loss = loss\n",
    "        self.checkpoint = tf.train.Checkpoint(step=tf.Variable(0),psnr=tf.Variable(-1.0),optimizer=Adam(learning_rate),model=model)\n",
    "        self.checkpoint_manager = tf.train.CheckpointManager(checkpoint=self.checkpoint, directory=checkpoint_dir, max_to_keep=3)\n",
    "        self.restore()\n",
    "    \n",
    "    @property\n",
    "    def model(self):\n",
    "        return self.checkpoint.model\n",
    "\n",
    "    def train(self, train_dataset, valid_dataset, steps, evaluate_every=1000, save_best_only=False):\n",
    "        loss_mean = Mean()\n",
    "\n",
    "        ckpt_mgr = self.checkpoint_manager\n",
    "        ckpt = self.checkpoint\n",
    "\n",
    "        self.now = time.perf_counter()\n",
    "\n",
    "        for lr, hr in train_dataset.take(steps - ckpt.step.numpy()):\n",
    "            ckpt.step.assign_add(1)\n",
    "            step = ckpt.step.numpy()\n",
    "\n",
    "            loss = self.train_step(lr, hr)\n",
    "            loss_mean(loss)\n",
    "\n",
    "            print(\"Currently in the train step \",step)\n",
    "\n",
    "            if step % evaluate_every == 0:\n",
    "                loss_value = loss_mean.result()\n",
    "                loss_mean.reset_states()\n",
    "\n",
    "                # Compute PSNR on validation dataset\n",
    "                psnr_value = self.evaluate(valid_dataset)\n",
    "\n",
    "                duration = time.perf_counter() - self.now\n",
    "                print(f'{step}/{steps}: loss = {loss_value.numpy():.3f}, PSNR = {psnr_value.numpy():3f} ({duration:.2f}s)')\n",
    "\n",
    "                if save_best_only and psnr_value <= ckpt.psnr:\n",
    "                    self.now = time.perf_counter()\n",
    "                    continue\n",
    "\n",
    "                ckpt.psnr = psnr_value\n",
    "                ckpt_mgr.save()\n",
    "\n",
    "                self.now = time.perf_counter()\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, lr, hr):\n",
    "        with tf.GradientTape() as tape:\n",
    "            lr = tf.cast(lr, tf.float32)\n",
    "            hr = tf.cast(hr, tf.float32)\n",
    "\n",
    "            sr = self.checkpoint.model(lr, training=True)\n",
    "            loss_value = self.loss(hr, sr)\n",
    "\n",
    "        gradients = tape.gradient(loss_value, self.checkpoint.model.trainable_variables)\n",
    "        self.checkpoint.optimizer.apply_gradients(zip(gradients, self.checkpoint.model.trainable_variables))\n",
    "\n",
    "        return loss_value\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "        return evaluate(self.checkpoint.model, dataset)\n",
    "\n",
    "    def restore(self):\n",
    "        if self.checkpoint_manager.latest_checkpoint:\n",
    "            self.checkpoint.restore(self.checkpoint_manager.latest_checkpoint)\n",
    "            print(f'Model restored from checkpoint at step {self.checkpoint.step.numpy()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SrganGeneratorTrainer(Trainer):\n",
    "    def __init__(self,model,checkpoint_dir,learning_rate=1e-4):\n",
    "        super().__init__(model, loss=MeanSquaredError(), learning_rate=learning_rate, checkpoint_dir=checkpoint_dir)\n",
    "\n",
    "    def train(self, train_dataset, valid_dataset, steps=50000, evaluate_every=1000, save_best_only=True):\n",
    "        super().train(train_dataset, valid_dataset, steps, evaluate_every, save_best_only)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SrganTrainer:\n",
    "    def __init__(self,generator,discriminator,content_loss='VGG54',learning_rate=PiecewiseConstantDecay(boundaries=[100000], values=[1e-4, 1e-5])):\n",
    "\n",
    "        if content_loss == 'VGG22':\n",
    "            self.vgg = srgan.vgg_22()\n",
    "        elif content_loss == 'VGG54':\n",
    "            self.vgg = srgan.vgg_54()\n",
    "        else:\n",
    "            raise ValueError(\"content_loss must be either 'VGG22' or 'VGG54'\")\n",
    "\n",
    "        self.content_loss = content_loss\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.generator_optimizer = Adam(learning_rate=learning_rate)\n",
    "        self.discriminator_optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "        self.binary_cross_entropy = BinaryCrossentropy(from_logits=False)\n",
    "        self.mean_squared_error = MeanSquaredError()\n",
    "\n",
    "    def train(self, train_dataset, steps=200000):\n",
    "        pls_metric = Mean()\n",
    "        dls_metric = Mean()\n",
    "        step = 0\n",
    "\n",
    "        for lr, hr in train_dataset.take(steps):\n",
    "            step += 1\n",
    "\n",
    "            pl, dl = self.train_step(lr, hr)\n",
    "            print(\"Currently in the sr-train step \",step)\n",
    "            pls_metric(pl)\n",
    "            dls_metric(dl)\n",
    "\n",
    "            if step % 50 == 0:\n",
    "                print(f'{step}/{steps}, perceptual loss = {pls_metric.result():.4f}, discriminator loss = {dls_metric.result():.4f}')\n",
    "                pls_metric.reset_states()\n",
    "                dls_metric.reset_states()\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, lr, hr):\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            lr = tf.cast(lr, tf.float32)\n",
    "            hr = tf.cast(hr, tf.float32)\n",
    "\n",
    "            sr = self.generator(lr, training=True)\n",
    "\n",
    "            hr_output = self.discriminator(hr, training=True)\n",
    "            sr_output = self.discriminator(sr, training=True)\n",
    "\n",
    "            con_loss = self._content_loss(hr, sr)\n",
    "            gen_loss = self._generator_loss(sr_output)\n",
    "            perc_loss = con_loss + 0.001 * gen_loss\n",
    "            disc_loss = self._discriminator_loss(hr_output, sr_output)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(perc_loss, self.generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "        self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "        self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "\n",
    "        return perc_loss, disc_loss\n",
    "\n",
    "    @tf.function\n",
    "    def _content_loss(self, hr, sr):\n",
    "        sr = preprocess_input(sr)\n",
    "        hr = preprocess_input(hr)\n",
    "        sr_features = self.vgg(sr) / 12.75\n",
    "        hr_features = self.vgg(hr) / 12.75\n",
    "        return self.mean_squared_error(hr_features, sr_features)\n",
    "\n",
    "    def _generator_loss(self, sr_out):\n",
    "        return self.binary_cross_entropy(tf.ones_like(sr_out), sr_out)\n",
    "\n",
    "    def _discriminator_loss(self, hr_out, sr_out):\n",
    "        hr_loss = self.binary_cross_entropy(tf.ones_like(hr_out), hr_out)\n",
    "        sr_loss = self.binary_cross_entropy(tf.zeros_like(sr_out), sr_out)\n",
    "        return hr_loss + sr_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "div2k_train = DIV2K(scale=4, subset='train', downgrade='bicubic')\n",
    "div2k_valid = DIV2K(scale=4, subset='valid', downgrade='bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = div2k_train.dataset(batch_size=16, random_transform=True)\n",
    "valid_ds = div2k_valid.dataset(batch_size=16, random_transform=True, repeat_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored from checkpoint at step 14000.\n",
      "Currently in the train step  14001\n",
      "Currently in the train step  14002\n",
      "Currently in the train step  14003\n",
      "Currently in the train step  14004\n",
      "Currently in the train step  14005\n"
     ]
    }
   ],
   "source": [
    "pre_trainer = SrganGeneratorTrainer(model=generator(), checkpoint_dir=f'.ckpt/pre_generator')\n",
    "pre_trainer.train(train_ds,valid_ds.take(10),steps=14005,evaluate_every=1000,save_best_only=False)\n",
    "\n",
    "CWD_PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Total params: 1,554,883\n",
      "Trainable params: 1,550,659\n",
      "Non-trainable params: 4,224\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(gan_generator.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 89 layers into a model with 0 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Zarrrr\\AI ultimate project\\SuperResolution-master\\train.ipynb Cell 10\u001b[0m in \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Zarrrr/AI%20ultimate%20project/SuperResolution-master/train.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Recreate the generator model with the same architecture\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Zarrrr/AI%20ultimate%20project/SuperResolution-master/train.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Zarrrr/AI%20ultimate%20project/SuperResolution-master/train.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Load the weights from the file\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Zarrrr/AI%20ultimate%20project/SuperResolution-master/train.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m loaded_weights_model \u001b[39m=\u001b[39m generator()  \u001b[39m# Recreate the model with the same architecture\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Zarrrr/AI%20ultimate%20project/SuperResolution-master/train.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m loaded_weights_model\u001b[39m.\u001b[39;49mload_weights(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(CWD_PATH, \u001b[39m'\u001b[39;49m\u001b[39mweights\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mpre_generator.h5\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Zarrrr/AI%20ultimate%20project/SuperResolution-master/train.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Compare the architectures\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Zarrrr/AI%20ultimate%20project/SuperResolution-master/train.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m gan_generator\u001b[39m.\u001b[39mget_config() \u001b[39m==\u001b[39m loaded_weights_model\u001b[39m.\u001b[39mget_config():\n",
      "File \u001b[1;32mc:\\Users\\DELL 5401\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2347\u001b[0m, in \u001b[0;36mModel.load_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2344\u001b[0m       hdf5_format\u001b[39m.\u001b[39mload_weights_from_hdf5_group_by_name(\n\u001b[0;32m   2345\u001b[0m           f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers, skip_mismatch\u001b[39m=\u001b[39mskip_mismatch)\n\u001b[0;32m   2346\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2347\u001b[0m       hdf5_format\u001b[39m.\u001b[39;49mload_weights_from_hdf5_group(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers)\n\u001b[0;32m   2349\u001b[0m \u001b[39m# Perform any layer defined finalization of the layer state.\u001b[39;00m\n\u001b[0;32m   2350\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n",
      "File \u001b[1;32mc:\\Users\\DELL 5401\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py:688\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    686\u001b[0m layer_names \u001b[39m=\u001b[39m filtered_layer_names\n\u001b[0;32m    687\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(layer_names) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(filtered_layers):\n\u001b[1;32m--> 688\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mYou are trying to load a weight file \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    689\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mcontaining \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(layer_names)) \u001b[39m+\u001b[39m\n\u001b[0;32m    690\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m layers into a model with \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(filtered_layers)) \u001b[39m+\u001b[39m\n\u001b[0;32m    691\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m layers.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    693\u001b[0m \u001b[39m# We batch weight value assignments in a single backend call\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[39m# which provides a speedup in TensorFlow.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m weight_value_tuples \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to load a weight file containing 89 layers into a model with 0 layers."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Recreate the generator model with the same architecture\n",
    "gan_generator = generator()\n",
    "\n",
    "# Load the weights from the file\n",
    "loaded_weights_model = generator()  # Recreate the model with the same architecture\n",
    "loaded_weights_model.load_weights(os.path.join(CWD_PATH, 'weights', 'pre_generator.h5'))\n",
    "\n",
    "# Compare the architectures\n",
    "if gan_generator.get_config() == loaded_weights_model.get_config():\n",
    "    print(\"The model architectures match.\")\n",
    "else:\n",
    "    print(\"The model architectures do not match.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 89 layers into a model with 0 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Zarrrr\\AI ultimate project\\SuperResolution-master\\train.ipynb Cell 9\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Zarrrr/AI%20ultimate%20project/SuperResolution-master/train.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gan_generator \u001b[39m=\u001b[39m generator()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Zarrrr/AI%20ultimate%20project/SuperResolution-master/train.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m gan_generator\u001b[39m.\u001b[39;49mload_weights(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(CWD_PATH, \u001b[39m'\u001b[39;49m\u001b[39mweights\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mpre_generator.h5\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\DELL 5401\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2347\u001b[0m, in \u001b[0;36mModel.load_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2344\u001b[0m       hdf5_format\u001b[39m.\u001b[39mload_weights_from_hdf5_group_by_name(\n\u001b[0;32m   2345\u001b[0m           f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers, skip_mismatch\u001b[39m=\u001b[39mskip_mismatch)\n\u001b[0;32m   2346\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2347\u001b[0m       hdf5_format\u001b[39m.\u001b[39;49mload_weights_from_hdf5_group(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers)\n\u001b[0;32m   2349\u001b[0m \u001b[39m# Perform any layer defined finalization of the layer state.\u001b[39;00m\n\u001b[0;32m   2350\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n",
      "File \u001b[1;32mc:\\Users\\DELL 5401\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py:688\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    686\u001b[0m layer_names \u001b[39m=\u001b[39m filtered_layer_names\n\u001b[0;32m    687\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(layer_names) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(filtered_layers):\n\u001b[1;32m--> 688\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mYou are trying to load a weight file \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    689\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mcontaining \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(layer_names)) \u001b[39m+\u001b[39m\n\u001b[0;32m    690\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m layers into a model with \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(filtered_layers)) \u001b[39m+\u001b[39m\n\u001b[0;32m    691\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m layers.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    693\u001b[0m \u001b[39m# We batch weight value assignments in a single backend call\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[39m# which provides a speedup in TensorFlow.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m weight_value_tuples \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to load a weight file containing 89 layers into a model with 0 layers."
     ]
    }
   ],
   "source": [
    "gan_generator = generator()\n",
    "gan_generator.load_weights(os.path.join(CWD_PATH, 'weights', 'pre_generator.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 89 layers into a model with 0 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Zarrrr\\AI ultimate project\\SuperResolution-master\\train.ipynb Cell 9\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Zarrrr/AI%20ultimate%20project/SuperResolution-master/train.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#To train gan\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Zarrrr/AI%20ultimate%20project/SuperResolution-master/train.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m gan_generator \u001b[39m=\u001b[39m generator()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Zarrrr/AI%20ultimate%20project/SuperResolution-master/train.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m gan_generator\u001b[39m.\u001b[39;49mload_weights(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(CWD_PATH,\u001b[39m'\u001b[39;49m\u001b[39mweights\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mpre_generator.h5\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Zarrrr/AI%20ultimate%20project/SuperResolution-master/train.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m gan_trainer \u001b[39m=\u001b[39m SrganTrainer(generator\u001b[39m=\u001b[39mgan_generator, discriminator\u001b[39m=\u001b[39mdiscriminator())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Zarrrr/AI%20ultimate%20project/SuperResolution-master/train.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m gan_trainer\u001b[39m.\u001b[39mtrain(train_ds, steps\u001b[39m=\u001b[39m\u001b[39m50000\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DELL 5401\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2347\u001b[0m, in \u001b[0;36mModel.load_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2344\u001b[0m       hdf5_format\u001b[39m.\u001b[39mload_weights_from_hdf5_group_by_name(\n\u001b[0;32m   2345\u001b[0m           f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers, skip_mismatch\u001b[39m=\u001b[39mskip_mismatch)\n\u001b[0;32m   2346\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2347\u001b[0m       hdf5_format\u001b[39m.\u001b[39;49mload_weights_from_hdf5_group(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers)\n\u001b[0;32m   2349\u001b[0m \u001b[39m# Perform any layer defined finalization of the layer state.\u001b[39;00m\n\u001b[0;32m   2350\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n",
      "File \u001b[1;32mc:\\Users\\DELL 5401\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py:688\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    686\u001b[0m layer_names \u001b[39m=\u001b[39m filtered_layer_names\n\u001b[0;32m    687\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(layer_names) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(filtered_layers):\n\u001b[1;32m--> 688\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mYou are trying to load a weight file \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    689\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mcontaining \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(layer_names)) \u001b[39m+\u001b[39m\n\u001b[0;32m    690\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m layers into a model with \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(filtered_layers)) \u001b[39m+\u001b[39m\n\u001b[0;32m    691\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m layers.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    693\u001b[0m \u001b[39m# We batch weight value assignments in a single backend call\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[39m# which provides a speedup in TensorFlow.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m weight_value_tuples \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to load a weight file containing 89 layers into a model with 0 layers."
     ]
    }
   ],
   "source": [
    "#To train gan\n",
    "gan_generator = generator()\n",
    "gan_generator.load_weights(os.path.join(CWD_PATH,'weights','pre_generator.h5'))\n",
    "\n",
    "gan_trainer = SrganTrainer(generator=gan_generator, discriminator=discriminator())\n",
    "gan_trainer.train(train_ds, steps=50000)\n",
    "\n",
    "gan_trainer.generator.save_weights(os.path.join(CWD_PATH,'weights','gan_generator.h5'))\n",
    "gan_trainer.discriminator.save_weights(os.path.join(CWD_PATH,'weights','gan_discriminator.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
